{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing the model's performance<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = False\n",
    "eval_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(41)\n",
    "torch.cuda.manual_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScanModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64,stride=1,kernel_size=3, bias=False)\n",
    "        self.conv2 = nn.Conv2d(64,64,stride=1,kernel_size=3, bias=False)\n",
    "        self.conv3 = nn.Conv2d(64,128,stride=1,kernel_size=3, bias=False)\n",
    "        self.conv4 = nn.Conv2d(128,256,stride=1,kernel_size=3, bias=False)\n",
    "        self.conv5 = nn.Conv2d(256,512, stride=1,kernel_size=3, bias=False)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(512,512, stride=1,kernel_size=3)#tuto layer nevim jestli pouzit\n",
    "\n",
    "        self.dropout = nn.Dropout(0.22)\n",
    "       \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.bn6 = nn.BatchNorm2d(512)\n",
    "         \n",
    "        self.fc1 = nn.Linear(512*5*5, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256,3)\n",
    "\n",
    "    def forward(self, x):       #toto se da udelat chytreji kdyz vytvorite funkci ktera vezme x a aplikuje ty 3 veci - conv,relu a dropout\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.bn4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.bn5(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        \n",
    "        x = x.view(-1,512*5*5)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x= self.dropout(x)\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "                   \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lexsu\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.Grayscale(num_output_channels=1),\n",
    "    v2.Resize((244,244)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.49], std=[0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.ImageFolder(root=\"Data/test\", # target folder of images\n",
    "                                  transform=transforms, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScanModel()\n",
    "model.load_state_dict(torch.load(\"CTscan_class_model_8epochs.pt\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScanModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout): Dropout(p=0.22, inplace=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=12800, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_correct = 0\n",
    "test_loss = 0\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Batch 0 done.\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Batch 3 done.\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 0\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Batch 6 done.\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Batch 9 done.\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 0, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 0\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Batch 12 done.\n",
      "Incorrect: 2, should be 0\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 0\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 0\n",
      "Incorrect: 2, should be 0\n",
      "Incorrect: 0, should be 2\n",
      "Incorrect: 2, should be 0\n",
      "Batch 15 done.\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 0\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Batch 18 done.\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 1, should be 2\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n",
      "Incorrect: 2, should be 1\n"
     ]
    }
   ],
   "source": [
    "if eval_mode:\n",
    "   with torch.no_grad():\n",
    "         for batch,(X_test,y_test) in enumerate(test_data):\n",
    "            X_test,y_test = X_test.to(device).float(), y_test.to(device)\n",
    "            y_val = model(X_test)\n",
    "            predicted = torch.max(y_val.detach(),1)[1] #detach udela to ze dostaneme cisty tensor z y_val a torch.max returne tuple dvou tensorů\n",
    "            # The first tensor contains the maximum values. The second tensor contains the indices where the maximum values occur.\n",
    "            for i in range(len(predicted)):\n",
    "               if predicted[i] == y_test[i]:\n",
    "                  test_correct += 1\n",
    "               else: print(f\"Incorrect: {predicted[i]}, should be {y_test[i]}\")\n",
    "               \n",
    "            #test_correct += (predicted == y_test).sum() # ten sum udela to ze to True nebo False pretvori v 1 or 0\n",
    "            if batch%3 == 0:\n",
    "               print(f\"Batch {batch} done.\")\n",
    "            loss = criterion(y_val,y_test)\n",
    "            test_loss += loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.329805850982666 \n",
      "Accuracy: 0.9262422360248447\n"
     ]
    }
   ],
   "source": [
    "if eval_mode:\n",
    "    lst1 = os.listdir('Data/test/COVID19')\n",
    "    lst2 = os.listdir('Data/test/NORMAL')\n",
    "    lst3 = os.listdir('Data/test/PNEUMONIA') # your directory path\n",
    "    lst = lst1 + lst2 + lst3\n",
    "    num_samples = len(lst)\n",
    "    print(f\"Loss: {test_loss} \\nAccuracy: {test_correct/num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>accuracy after 5 epochs of training: ~ 83.2%<h5>\n",
    "<h5>accuracy after 6 epochs of training: ~ 92.7%<h5>\n",
    "<h5>accuracy after 8 epochs of training: ~ 92.6%<h5>\n",
    "We could improve this by augumenting our data (mainly for covid samples) and thus balancing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Continuing the training<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "None (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\lexsu\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3526\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[78], line 2\u001b[1;36m\n\u001b[1;33m    raise SyntaxError\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not train_mode:\n",
    "    raise SyntaxError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=\"Data/train\", transform=transforms)\n",
    "train_data = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1   Batch: 1   Loss: 0.12195540964603424\n",
      "Epoch: 1   Batch: 11   Loss: 0.06627944856882095\n",
      "Epoch: 1   Batch: 21   Loss: 0.15441067516803741\n",
      "Epoch: 1   Batch: 31   Loss: 0.20309525728225708\n",
      "Epoch: 1   Batch: 41   Loss: 0.05238477140665054\n",
      "Epoch: 1   Batch: 51   Loss: 0.10936272144317627\n",
      "Epoch: 1   Batch: 61   Loss: 0.061345960944890976\n",
      "Epoch: 1   Batch: 71   Loss: 0.059761181473731995\n",
      "Epoch: 1   Batch: 81   Loss: 0.1293635070323944\n",
      "Epoch: 2   Batch: 1   Loss: 0.10435722768306732\n",
      "Epoch: 2   Batch: 11   Loss: 0.1989828497171402\n",
      "Epoch: 2   Batch: 21   Loss: 0.12737734615802765\n",
      "Epoch: 2   Batch: 31   Loss: 0.1885148286819458\n",
      "Epoch: 2   Batch: 41   Loss: 0.04979225620627403\n",
      "Epoch: 2   Batch: 51   Loss: 0.1975577175617218\n",
      "Epoch: 2   Batch: 61   Loss: 0.13188600540161133\n",
      "Epoch: 2   Batch: 71   Loss: 0.07148662954568863\n",
      "Epoch: 2   Batch: 81   Loss: 0.009582582861185074\n",
      "Training took 7.511333040396372 minutes.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_correct = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    epoch_train_correct = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X_train,y_train) in enumerate(train_data):\n",
    "      X_train,y_train = X_train.to(device).float(), y_train.to(device)\n",
    "      y_pred = model.forward(X_train)\n",
    "      loss = criterion(y_pred,y_train)\n",
    "\n",
    "      predicted = torch.max(y_pred.detach(),1)[1]   # .data oddelí gradient atd od samostatných dat a dá nám jen data, ta jednice v tom maxu znamena dimenze na ktere hleda max(cols nebo rows asi)\n",
    "      batch_correct = (predicted == y_train).sum()\n",
    "      epoch_train_correct += batch_correct\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward() #vypocita gradient pro nase weights atd\n",
    "      optimizer.step() #updatne weights s gradientem\n",
    "\n",
    "      if batch%10 == 0:\n",
    "        print(f\"Epoch: {epoch+1}   Batch: {batch+1}   Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_losses.append((f\"Trl{epoch+1}\",loss))\n",
    "    train_correct.append((f\"Trc{epoch+1}\",epoch_train_correct))\n",
    "\n",
    "\n",
    "current_time = time.time()\n",
    "total_time = current_time - start_time\n",
    "print(f\"Training took {total_time/60} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CTscan_class_model_8epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
